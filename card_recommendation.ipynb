{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "75dd5bf841fa4a61b30e3d4bee74dc23",
            "6b9c1d412c494a93959eb6863917b7f5",
            "dc053265641944509b5cdc276fb39db5",
            "737ce19ab5774fa2b4468ae6c7a83620",
            "6749d9e901f441e68df83b1293244867",
            "ad3029bbb3b0437eabd71b33cbeebc94",
            "c0ae8c5401694ab08a70f1d83bf9145b",
            "217736ea93ec46d183e0ec8b90fdaa82",
            "5a35688a42e64125bf22fa5f8b67c2c0",
            "018bbb6619ee455a9bde3f6e5d6f2f42",
            "38fa0b60ecb6433c8ab3db973f0da329"
          ]
        },
        "id": "kfE5uC6T0gwA",
        "outputId": "f3d010e2-9b60-4ceb-c2a7-990808c00163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.11/dist-packages (1.17)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "LightFM 라이브러리가 성공적으로 로드되었습니다.\n",
            "TensorFlow 라이브러리가 성공적으로 로드되었습니다.\n",
            "cus_card.csv 파일을 업로드하세요.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2abad2fc-8217-40f6-b147-493f356db509\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2abad2fc-8217-40f6-b147-493f356db509\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving cus_card.csv to cus_card (1).csv\n",
            "\n",
            "cards.csv 파일을 업로드하세요.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a9d811b-0401-4a57-8606-bcf73fa1c4f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a9d811b-0401-4a57-8606-bcf73fa1c4f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving cards.csv to cards (1).csv\n",
            "\n",
            "benefits.csv 파일을 업로드하세요.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e75b996-c88e-4fa6-af4a-b4db371609c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7e75b996-c88e-4fa6-af4a-b4db371609c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving benefits.csv to benefits (1).csv\n",
            "\n",
            "woori_10pct_labeled.csv 파일을 업로드하세요.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11eda235-b815-48c5-9bdf-c991505541a9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11eda235-b815-48c5-9bdf-c991505541a9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving woori_10pct_labeled.csv to woori_10pct_labeled (1).csv\n",
            "'SEQ' 열을 'customer_id'로 이름 변경했습니다.\n",
            "고객 수: 45955\n",
            "카드 수: 200\n",
            "혜택 수: 1185\n",
            "클러스터 데이터 수: 45955\n",
            "\n",
            "클러스터 분포:\n",
            "cluster\n",
            "1    16999\n",
            "2    11996\n",
            "7     6916\n",
            "4     4325\n",
            "6     1645\n",
            "3     1595\n",
            "0     1428\n",
            "5     1051\n",
            "Name: count, dtype: int64\n",
            "상호작용 데이터 건수: 91859\n",
            "전처리 후 고객 수: 45955\n",
            "전처리 후 카드 수: 198\n",
            "카드 특성 행렬 크기: (198, 100)\n",
            "사용자 특성 행렬 크기: (45955, 12)\n",
            "LightFM 클러스터별 모델 훈련 중...\n",
            "\n",
            "클러스터 1 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:04<00:00,  7.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 1 LightFM Hit Rate: 0.0796\n",
            "\n",
            "클러스터 2 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:03<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 2 LightFM Hit Rate: 0.0817\n",
            "\n",
            "클러스터 5 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:00<00:00, 82.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 5 LightFM Hit Rate: 0.0593\n",
            "\n",
            "클러스터 7 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:02<00:00, 14.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 7 LightFM Hit Rate: 0.0724\n",
            "\n",
            "클러스터 4 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:01<00:00, 25.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 4 LightFM Hit Rate: 0.0793\n",
            "\n",
            "클러스터 3 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:00<00:00, 63.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 3 LightFM Hit Rate: 0.0885\n",
            "\n",
            "클러스터 0 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:00<00:00, 67.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 0 LightFM Hit Rate: 0.0717\n",
            "\n",
            "클러스터 6 LightFM 모델 훈련 중...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 30/30 [00:00<00:00, 36.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클러스터 6 LightFM Hit Rate: 0.0753\n",
            "\n",
            "DeepFM 클러스터별 모델 훈련 중...\n",
            "feature_cols 정의: 111개 특성\n",
            "\n",
            "클러스터 1 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (27216, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (6665, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 1 DeepFM 모델 훈련 시작...\n",
            "클러스터 1 DeepFM 모델 훈련 완료\n",
            "클러스터 1 DeepFM Hit Rate: 0.0553\n",
            "\n",
            "클러스터 2 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (19193, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (4893, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 2 DeepFM 모델 훈련 시작...\n",
            "클러스터 2 DeepFM 모델 훈련 완료\n",
            "클러스터 2 DeepFM Hit Rate: 0.0570\n",
            "\n",
            "클러스터 5 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (1722, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (422, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 5 DeepFM 모델 훈련 시작...\n",
            "클러스터 5 DeepFM 모델 훈련 완료\n",
            "클러스터 5 DeepFM Hit Rate: 0.0701\n",
            "\n",
            "클러스터 7 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (11085, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (2774, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 7 DeepFM 모델 훈련 시작...\n",
            "클러스터 7 DeepFM 모델 훈련 완료\n",
            "클러스터 7 DeepFM Hit Rate: 0.0517\n",
            "\n",
            "클러스터 4 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (6928, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (1744, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 4 DeepFM 모델 훈련 시작...\n",
            "클러스터 4 DeepFM 모델 훈련 완료\n",
            "클러스터 4 DeepFM Hit Rate: 0.0535\n",
            "\n",
            "클러스터 3 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (2490, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (645, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 3 DeepFM 모델 훈련 시작...\n",
            "클러스터 3 DeepFM 모델 훈련 완료\n",
            "클러스터 3 DeepFM Hit Rate: 0.0637\n",
            "\n",
            "클러스터 0 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (2300, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (532, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 0 DeepFM 모델 훈련 시작...\n",
            "클러스터 0 DeepFM 모델 훈련 완료\n",
            "클러스터 0 DeepFM Hit Rate: 0.0422\n",
            "\n",
            "클러스터 6 DeepFM 모델 훈련 중...\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (2553, 111)\n",
            "prepare_deepfm_data 호출: feature_cols 길이 = 111\n",
            "prepare_deepfm_data: 특성 컬럼 수 = 111, 특성 행렬 크기 = (697, 111)\n",
            "DeepFM 모델 구축: 입력 특성 차원 = 111\n",
            "FMLayer 초기화: 특성 차원 = 111, 임베딩 크기 = 16\n",
            "클러스터 6 DeepFM 모델 훈련 시작...\n",
            "클러스터 6 DeepFM 모델 훈련 완료\n",
            "클러스터 6 DeepFM Hit Rate: 0.0491\n",
            "\n",
            "클러스터별 최적 알고리즘 선택:\n",
            "클러스터 1: LightFM (Hit Rate: 0.0796)\n",
            "클러스터 2: LightFM (Hit Rate: 0.0817)\n",
            "클러스터 5: DeepFM (Hit Rate: 0.0701)\n",
            "클러스터 7: LightFM (Hit Rate: 0.0724)\n",
            "클러스터 4: LightFM (Hit Rate: 0.0793)\n",
            "클러스터 3: LightFM (Hit Rate: 0.0885)\n",
            "클러스터 0: LightFM (Hit Rate: 0.0717)\n",
            "클러스터 6: LightFM (Hit Rate: 0.0753)\n",
            "\n",
            "고객별 추천 카드 생성 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75dd5bf841fa4a61b30e3d4bee74dc23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/45955 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "추천 결과가 card_recommendations.csv 파일로 저장되었습니다.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b555277f-2a24-4a56-a2d3-2ed41f982d7d\", \"card_recommendations.csv\", 11450858)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 카드 추천 시스템 구현 결과 ===\n",
            "총 고객 수: 45955\n",
            "총 추천 고객 수: 45955\n",
            "클러스터 수: 8\n",
            "\n",
            "클러스터별 최적 알고리즘:\n",
            "클러스터 1: LightFM (Hit Rate: 0.0796)\n",
            "클러스터 2: LightFM (Hit Rate: 0.0817)\n",
            "클러스터 5: DeepFM (Hit Rate: 0.0701)\n",
            "클러스터 7: LightFM (Hit Rate: 0.0724)\n",
            "클러스터 4: LightFM (Hit Rate: 0.0793)\n",
            "클러스터 3: LightFM (Hit Rate: 0.0885)\n",
            "클러스터 0: LightFM (Hit Rate: 0.0717)\n",
            "클러스터 6: LightFM (Hit Rate: 0.0753)\n",
            "\n",
            "추천 샘플 (5명):\n",
            "고객 ID: HSR6P43LIMPS12N0UZZ9\n",
            "  1. zgm.the pay카드\n",
            "  2. 신한카드 The BEST-F\n",
            "  3. 카드의정석 EVERY MILE SKYPASS\n",
            "  4. 트래블로그 체크카드\n",
            "  5. the Green Edition2\n",
            "\n",
            "고객 ID: 9GDU0YYKZ0EKNHIALX39\n",
            "  1. 신한카드 플리 체크(산리오캐릭터즈)\n",
            "  2. 신한카드 플리(산리오캐릭터즈)\n",
            "  3. 삼성 iD EV 카드\n",
            "  4. 마일앤조이카드(아시아나)\n",
            "  5. taptap DIGITAL\n",
            "\n",
            "고객 ID: AKOKJ7B1KBN723LTNHT8\n",
            "  1. 노리2 체크카드(Play)\n",
            "  2. 노리2 체크카드(Global)\n",
            "  3. 케이뱅크 플러스 체크카드\n",
            "  4. 트래블페이 충전카드\n",
            "  5. 토스뱅크카드\n",
            "\n",
            "고객 ID: F4XRBTIB1LNXY8MQXGZY\n",
            "  1. the Red Edition5\n",
            "  2. 카카오페이 체크카드\n",
            "  3. PAYCO 포인트 카드\n",
            "  4. 메리어트 본보이™ 더 베스트 신한카드\n",
            "  5. 네이버페이 머니카드\n",
            "\n",
            "고객 ID: 6N6OZ8CANCIEI11MA6YP\n",
            "  1. 올바른 FLEX 카드\n",
            "  2. NH올원 파이카드\n",
            "  3. 올바른POINT체크카드\n",
            "  4. NH올원 Shopping&11번가카드(R2타입)\n",
            "  5. 카드의정석 L.POINT CHECK\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "카드 추천 시스템 구현 - LightFM과 DeepFM 알고리즘 적용 (Google Colab 버전)\n",
        "- LightFM: 하이브리드 추천 시스템(협업 필터링 + 컨텐츠 기반)\n",
        "- DeepFM: 딥러닝 기반 추천 시스템(FM + Deep Neural Network)\n",
        "- Hit Rate 평가지표 사용\n",
        "\"\"\"\n",
        "\n",
        "# ## 1. 필요한 라이브러리 설치 및 임포트\n",
        "\n",
        "# %%\n",
        "# 필요한 라이브러리 설치\n",
        "#!pip install lightfm pandas numpy scikit-learn tensorflow scipy matplotlib tqdm\n",
        "\n",
        "# %%\n",
        "# 라이브러리 임포트\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "from google.colab import files  # 파일 업로드를 위한 Colab 전용 기능\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LightFM 임포트 시도\n",
        "try:\n",
        "    from lightfm import LightFM\n",
        "    from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "    LIGHTFM_AVAILABLE = True\n",
        "    print(\"LightFM 라이브러리가 성공적으로 로드되었습니다.\")\n",
        "except ImportError:\n",
        "    LIGHTFM_AVAILABLE = False\n",
        "    print(\"경고: LightFM 라이브러리를 불러올 수 없습니다. LightFM 기능이 비활성화됩니다.\")\n",
        "\n",
        "# TensorFlow 임포트\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras import layers, Model, optimizers\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(\"TensorFlow 라이브러리가 성공적으로 로드되었습니다.\")\n",
        "except ImportError:\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "    print(\"경고: TensorFlow 라이브러리를 불러올 수 없습니다. DeepFM 기능이 비활성화됩니다.\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2. 데이터 업로드 및 확인\n",
        "# 데이터 파일을 Google Colab에 업로드합니다. 코랩에서는 files.upload() 함수를 사용하여 파일을 업로드할 수 있습니다.\n",
        "\n",
        "# %%\n",
        "# Google Colab에 파일 업로드 (실행 후 파일 선택 대화상자에서 파일 선택)\n",
        "print(\"cus_card.csv 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()  # cus_card.csv 파일 업로드\n",
        "\n",
        "print(\"\\ncards.csv 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()  # cards.csv 파일 업로드\n",
        "\n",
        "print(\"\\nbenefits.csv 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()  # benefits.csv 파일 업로드\n",
        "\n",
        "print(\"\\nwoori_10pct_labeled.csv 파일을 업로드하세요.\")\n",
        "uploaded = files.upload()  # woori_10pct_labeled.csv 파일 업로드\n",
        "\n",
        "# %%\n",
        "# 데이터 로드\n",
        "df_cus_card = pd.read_csv('cus_card.csv')\n",
        "df_cards = pd.read_csv('cards.csv')\n",
        "df_benefits = pd.read_csv('benefits.csv')\n",
        "df_clusters = pd.read_csv('woori_10pct_labeled.csv')\n",
        "\n",
        "# 'SEQ' 열이 있으면 'customer_id'로 이름 변경\n",
        "if 'SEQ' in df_clusters.columns and 'customer_id' not in df_clusters.columns:\n",
        "    df_clusters.rename(columns={'SEQ': 'customer_id'}, inplace=True)\n",
        "    print(\"'SEQ' 열을 'customer_id'로 이름 변경했습니다.\")\n",
        "\n",
        "# 데이터 정보 출력\n",
        "print(f\"고객 수: {df_cus_card.shape[0]}\")\n",
        "print(f\"카드 수: {df_cards.shape[0]}\")\n",
        "print(f\"혜택 수: {df_benefits.shape[0]}\")\n",
        "print(f\"클러스터 데이터 수: {df_clusters.shape[0]}\")\n",
        "\n",
        "# 클러스터 정보 확인\n",
        "print(\"\\n클러스터 분포:\")\n",
        "print(df_clusters['cluster'].value_counts())\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. 데이터 전처리\n",
        "\n",
        "# %%\n",
        "# 고객별 보유 카드 정보 전처리\n",
        "def preprocess_customer_card_data(df_cus_card, df_cards):\n",
        "    # 고객별 보유 카드 목록 생성\n",
        "    customer_cards = {}\n",
        "    for _, row in df_cus_card.iterrows():\n",
        "        customer_id = row['customer_id']\n",
        "        cards = [card_name for col in df_cus_card.columns if '보유카드' in col\n",
        "                for card_name in [row[col]] if pd.notna(card_name)]\n",
        "        customer_cards[customer_id] = cards\n",
        "\n",
        "    # 보유 카드 이름을 카드 ID로 매핑\n",
        "    card_name_to_id = {}\n",
        "    for _, row in df_cards.iterrows():\n",
        "        card_name_to_id[row['card_name']] = row['card_id']\n",
        "\n",
        "    # 고객-카드 상호작용 데이터 생성\n",
        "    interactions = []\n",
        "    for customer_id, cards in customer_cards.items():\n",
        "        for card_name in cards:\n",
        "            if card_name in card_name_to_id:\n",
        "                interactions.append((customer_id, card_name_to_id[card_name]))\n",
        "\n",
        "    df_interactions = pd.DataFrame(data=interactions, columns=['customer_id', 'card_id'])\n",
        "    return df_interactions\n",
        "\n",
        "# 카드 혜택 정보 전처리\n",
        "def preprocess_card_benefits(df_benefits):\n",
        "    # 카드별 혜택 텍스트 합치기\n",
        "    card_benefits = df_benefits.groupby('card_id')['benefit_text'].apply(\n",
        "        lambda x: ' '.join(x)).reset_index()\n",
        "    return card_benefits\n",
        "\n",
        "# 상호작용 데이터 생성\n",
        "df_interactions = preprocess_customer_card_data(df_cus_card, df_cards)\n",
        "print(f\"상호작용 데이터 건수: {df_interactions.shape[0]}\")\n",
        "\n",
        "# 카드 혜택 정보 처리\n",
        "df_card_benefits = preprocess_card_benefits(df_benefits)\n",
        "\n",
        "# 소비 패턴과 클러스터 정보 병합\n",
        "df_customer_profile = df_clusters.copy()\n",
        "\n",
        "# 사용자와 아이템 인덱스 생성\n",
        "customer_encoder = LabelEncoder()\n",
        "card_encoder = LabelEncoder()\n",
        "\n",
        "df_interactions['customer_idx'] = customer_encoder.fit_transform(\n",
        "    df_interactions['customer_id'].values\n",
        ")\n",
        "df_interactions['card_idx'] = card_encoder.fit_transform(\n",
        "    df_interactions['card_id'].values\n",
        ")\n",
        "\n",
        "# 고객 및 카드 수 계산\n",
        "n_customers = df_interactions['customer_idx'].nunique()\n",
        "n_cards = df_interactions['card_idx'].nunique()\n",
        "\n",
        "print(f\"전처리 후 고객 수: {n_customers}\")\n",
        "print(f\"전처리 후 카드 수: {n_cards}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. 모델링을 위한 데이터 준비\n",
        "\n",
        "# %%\n",
        "# 훈련 및 테스트 세트 분리\n",
        "train_interactions, test_interactions = train_test_split(df_interactions, test_size=0.2, random_state=42)\n",
        "\n",
        "# ID를 인덱스로 매핑하는 딕셔너리 생성\n",
        "customer_id_to_idx = dict(zip(customer_encoder.classes_, range(len(customer_encoder.classes_))))\n",
        "card_id_to_idx = dict(zip(card_encoder.classes_, range(len(card_encoder.classes_))))\n",
        "\n",
        "# LightFM용 상호작용 행렬 생성\n",
        "def create_interaction_matrix(df, n_users, n_items, user_col, item_col):\n",
        "    user_indices = df[user_col].values\n",
        "    item_indices = df[item_col].values\n",
        "    values = np.ones(len(df), dtype=np.float32)\n",
        "\n",
        "    return sparse.coo_matrix((values, (user_indices, item_indices)),\n",
        "                          shape=(n_users, n_items), dtype=np.float32)\n",
        "\n",
        "# LightFM용 행렬 생성\n",
        "train_matrix = create_interaction_matrix(\n",
        "    train_interactions,\n",
        "    n_customers,\n",
        "    n_cards,\n",
        "    'customer_idx',\n",
        "    'card_idx'\n",
        ")\n",
        "# coo_matrix를 csr_matrix로 변환 (인덱싱 가능하도록)\n",
        "train_matrix = train_matrix.tocsr()\n",
        "\n",
        "test_matrix = create_interaction_matrix(\n",
        "    test_interactions,\n",
        "    n_customers,\n",
        "    n_cards,\n",
        "    'customer_idx',\n",
        "    'card_idx'\n",
        ")\n",
        "# coo_matrix를 csr_matrix로 변환 (인덱싱 가능하도록)\n",
        "test_matrix = test_matrix.tocsr()\n",
        "\n",
        "# 클러스터 ID 저장\n",
        "cluster_ids = df_customer_profile['cluster'].unique()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5. 특성(Feature) 행렬 생성\n",
        "\n",
        "# %%\n",
        "# 카드 특성 생성 (TF-IDF로 혜택 텍스트 벡터화)\n",
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "\n",
        "# 카드 혜택 데이터 준비\n",
        "card_texts = []\n",
        "for idx in range(n_cards):\n",
        "    card_id = card_encoder.inverse_transform([idx])[0]\n",
        "    benefit_texts = df_card_benefits[df_card_benefits['card_id'] == card_id]['benefit_text'].tolist()\n",
        "    if len(benefit_texts) > 0:\n",
        "        card_texts.append(benefit_texts[0])\n",
        "    else:\n",
        "        card_texts.append(\"\")\n",
        "\n",
        "# TF-IDF 벡터화\n",
        "card_features_matrix = tfidf.fit_transform(card_texts)\n",
        "print(f\"카드 특성 행렬 크기: {card_features_matrix.shape}\")\n",
        "\n",
        "# 사용자 특성 생성\n",
        "# 소비 패턴 컬럼만 선택\n",
        "feature_cols = [col for col in df_customer_profile.columns\n",
        "               if col not in ['SEQ', 'customer_id', 'cluster']]\n",
        "\n",
        "user_features = np.zeros((int(n_customers), len(feature_cols) + 1))  # +1 for cluster\n",
        "\n",
        "for _, row in df_customer_profile.iterrows():\n",
        "    if row['customer_id'] in customer_id_to_idx:\n",
        "        idx = customer_id_to_idx[row['customer_id']]\n",
        "        feature_values = row[feature_cols].tolist()\n",
        "        user_features[idx, :-1] = feature_values\n",
        "        user_features[idx, -1] = row['cluster']  # 클러스터 정보 추가\n",
        "\n",
        "# 표준화\n",
        "scaler = StandardScaler()\n",
        "user_features = scaler.fit_transform(user_features)\n",
        "user_features_matrix = sparse.csr_matrix(user_features)\n",
        "print(f\"사용자 특성 행렬 크기: {user_features_matrix.shape}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. LightFM 모델 구현 및 훈련\n",
        "\n",
        "# %%\n",
        "if LIGHTFM_AVAILABLE:\n",
        "    # LightFM 모델 평가 함수\n",
        "    def calculate_lightfm_hit_rate(model, user_indices, full_test_matrix, full_train_matrix, n=10):\n",
        "        \"\"\"LightFM Hit Rate 계산\"\"\"\n",
        "        hits = 0\n",
        "        total_users = 0\n",
        "\n",
        "        for user_idx in user_indices:\n",
        "            try:\n",
        "                # 테스트 세트의 실제 항목\n",
        "                test_items = full_test_matrix[user_idx].indices\n",
        "                if len(test_items) == 0:\n",
        "                    continue\n",
        "\n",
        "                # 훈련 세트에서 이미 상호작용한 항목\n",
        "                train_items = full_train_matrix[user_idx].indices\n",
        "\n",
        "                # 모든 아이템에 대한 예측 점수 계산 - 사용자 특성을 개별적으로 전달하지 않음\n",
        "                scores = model.predict(\n",
        "                    user_idx,\n",
        "                    np.arange(n_cards),\n",
        "                    user_features=None,  # 사용자 특성 매개변수 제거\n",
        "                    item_features=card_features_matrix\n",
        "                )\n",
        "\n",
        "                # 훈련 세트의 항목 점수 낮추기\n",
        "                scores[train_items] = -np.inf\n",
        "\n",
        "                # 상위 N개 아이템 선택\n",
        "                top_items = np.argsort(-scores)[:n]\n",
        "\n",
        "                # 상위 N개 중 실제 아이템이 있는지 확인\n",
        "                if np.intersect1d(top_items, test_items).size > 0:\n",
        "                    hits += 1\n",
        "\n",
        "                total_users += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"사용자 {user_idx} 평가 중 오류: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        hit_rate = hits / total_users if total_users > 0 else 0\n",
        "        return hit_rate\n",
        "\n",
        "    print(\"LightFM 클러스터별 모델 훈련 중...\")\n",
        "    # 클러스터별 모델과 평가 결과 저장\n",
        "    lightfm_models = {}\n",
        "    lightfm_hit_rates = {}\n",
        "\n",
        "    for cluster in cluster_ids:\n",
        "        print(f\"\\n클러스터 {cluster} LightFM 모델 훈련 중...\")\n",
        "\n",
        "        # 클러스터에 해당하는 사용자 인덱스 추출\n",
        "        cluster_users = df_customer_profile[\n",
        "            df_customer_profile['cluster'] == cluster]['customer_id'].tolist()\n",
        "        cluster_user_indices = [customer_id_to_idx[user_id]\n",
        "                            for user_id in cluster_users\n",
        "                            if user_id in customer_id_to_idx]\n",
        "\n",
        "        if len(cluster_user_indices) == 0:\n",
        "            lightfm_hit_rates[cluster] = 0\n",
        "            continue\n",
        "\n",
        "        # 클러스터별 훈련 및 테스트 행렬 생성\n",
        "        cluster_train_matrix = sparse.lil_matrix(train_matrix.shape)\n",
        "        cluster_test_matrix = sparse.lil_matrix(test_matrix.shape)\n",
        "\n",
        "        # 해당 클러스터 사용자의 데이터만 추출\n",
        "        for user_idx in cluster_user_indices:\n",
        "            cluster_train_matrix[user_idx] = train_matrix[user_idx]\n",
        "            cluster_test_matrix[user_idx] = test_matrix[user_idx]\n",
        "\n",
        "        # csr 형식으로 변환 (효율적인 연산을 위해)\n",
        "        cluster_train_matrix = cluster_train_matrix.tocsr()\n",
        "        cluster_test_matrix = cluster_test_matrix.tocsr()\n",
        "\n",
        "        # LightFM 모델 초기화 및 훈련 - 클러스터별 별도 모델\n",
        "        lightfm_model = LightFM(loss='warp', no_components=30, learning_rate=0.05, random_state=42)\n",
        "\n",
        "        # 모델 훈련 (클러스터별 데이터로)\n",
        "        lightfm_model.fit(\n",
        "            cluster_train_matrix,\n",
        "            user_features=None,\n",
        "            item_features=card_features_matrix,\n",
        "            epochs=30,\n",
        "            num_threads=4,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # 모델 저장\n",
        "        lightfm_models[cluster] = lightfm_model\n",
        "\n",
        "        # 클러스터별 모델 평가\n",
        "        hit_rate = calculate_lightfm_hit_rate(\n",
        "            lightfm_model,\n",
        "            cluster_user_indices,\n",
        "            cluster_test_matrix,\n",
        "            cluster_train_matrix,\n",
        "            n=10\n",
        "        )\n",
        "        lightfm_hit_rates[cluster] = hit_rate\n",
        "        print(f\"클러스터 {cluster} LightFM Hit Rate: {hit_rate:.4f}\")\n",
        "else:\n",
        "    print(\"LightFM 라이브러리를 사용할 수 없어 훈련을 건너뜁니다.\")\n",
        "    lightfm_models = {}\n",
        "    lightfm_hit_rates = {}\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 7. DeepFM 모델 구현 및 훈련\n",
        "\n",
        "# %%\n",
        "if TENSORFLOW_AVAILABLE:\n",
        "    print(\"\\nDeepFM 클러스터별 모델 훈련 중...\")\n",
        "\n",
        "    # DeepFM 모델 구현\n",
        "    class FMLayer(layers.Layer):\n",
        "        def __init__(self, feature_dim, embedding_size=10, **kwargs):\n",
        "            super(FMLayer, self).__init__(**kwargs)\n",
        "            self.feature_dim = feature_dim\n",
        "            self.embedding_size = embedding_size\n",
        "            # 특성 차원이 너무 크면 임베딩 크기를 조정\n",
        "            print(f\"FMLayer 초기화: 특성 차원 = {feature_dim}, 임베딩 크기 = {embedding_size}\")\n",
        "            self.embedding_layer = layers.Embedding(feature_dim, embedding_size)\n",
        "\n",
        "        def call(self, inputs):\n",
        "            # 피처 범위\n",
        "            feature_range = tf.range(self.feature_dim, dtype=tf.int32)\n",
        "\n",
        "            # 임베딩\n",
        "            embeddings = self.embedding_layer(feature_range)\n",
        "\n",
        "            # 피처별 임베딩 적용\n",
        "            feature_embeddings = tf.multiply(\n",
        "                tf.expand_dims(inputs, axis=-1),\n",
        "                embeddings\n",
        "            )\n",
        "\n",
        "            # FM 2차 상호작용 계산\n",
        "            summed_square = tf.square(tf.reduce_sum(feature_embeddings, axis=1))\n",
        "            squared_sum = tf.reduce_sum(tf.square(feature_embeddings), axis=1)\n",
        "            # 리듀스 차원을 추가하여 스칼라로 변환\n",
        "            fm_interaction = tf.reduce_sum(0.5 * tf.subtract(summed_square, squared_sum), axis=1, keepdims=True)\n",
        "            return fm_interaction\n",
        "\n",
        "    class DeepFM:\n",
        "        def __init__(self, feature_dim, embedding_size=10, dnn_hidden_units=[64, 32, 16]):\n",
        "            self.feature_dim = feature_dim\n",
        "            self.embedding_size = embedding_size\n",
        "            self.dnn_hidden_units = dnn_hidden_units\n",
        "            self.model = self.build_model()\n",
        "\n",
        "        def build_model(self):\n",
        "            # 입력 레이어 - 실제 특성 차원 사용\n",
        "            print(f\"DeepFM 모델 구축: 입력 특성 차원 = {self.feature_dim}\")\n",
        "            inputs = layers.Input(shape=(self.feature_dim,))\n",
        "\n",
        "            # FM 부분\n",
        "            # 선형(1차) 부분\n",
        "            linear_output = layers.Dense(1)(inputs)\n",
        "\n",
        "            # 2차 상호작용 부분 - 커스텀 레이어 사용\n",
        "            fm_output = FMLayer(self.feature_dim, self.embedding_size)(inputs)\n",
        "\n",
        "            # DNN 부분\n",
        "            dnn_output = inputs\n",
        "            for units in self.dnn_hidden_units:\n",
        "                dnn_output = layers.Dense(units, activation='relu')(dnn_output)\n",
        "            dnn_output = layers.Dense(1)(dnn_output)\n",
        "\n",
        "            # 최종 출력 - fm_output이 이미 (batch_size, 1) 형태로 출력됨\n",
        "            outputs = layers.Add()([linear_output, fm_output, dnn_output])\n",
        "            outputs = layers.Activation('sigmoid')(outputs)\n",
        "\n",
        "            # 모델 컴파일\n",
        "            model = Model(inputs=inputs, outputs=outputs)\n",
        "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "            return model\n",
        "\n",
        "    # DeepFM 모델용 데이터 준비\n",
        "    def prepare_deepfm_data(df_interactions, df_customer_profile, card_features_matrix, card_encoder):\n",
        "        # 전역 feature_cols 변수 사용\n",
        "        global feature_cols, feature_dim\n",
        "        print(f\"prepare_deepfm_data 호출: feature_cols 길이 = {len(feature_cols)}\")\n",
        "\n",
        "        # 사용자-카드 특성 결합\n",
        "        df = df_interactions.copy()\n",
        "\n",
        "        # 카드 특성 추가\n",
        "        df['card_type'] = df['card_id'].apply(lambda x: 1 if x >= 1000 else 0)  # 카드 유형(체크=0, 신용=1)\n",
        "\n",
        "        # 사용자 특성 추가\n",
        "        df = pd.merge(\n",
        "            df,\n",
        "            df_customer_profile[['customer_id', 'cluster', 'TOT_USE_AM']],\n",
        "            on='customer_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 카드 혜택 정보 추가 (단순화)\n",
        "        df['has_benefits'] = df['card_id'].apply(\n",
        "            lambda x: 1 if x in df_card_benefits['card_id'].values else 0\n",
        "        )\n",
        "\n",
        "        # 원-핫 인코딩\n",
        "        clusters_onehot = pd.get_dummies(df['cluster'], prefix='cluster')\n",
        "        df = pd.concat([df, clusters_onehot], axis=1)\n",
        "\n",
        "        # 카드 ID를 카드 인덱스로 변환하여 TF-IDF 특성 추가\n",
        "        card_id_to_idx = {card_id: idx for idx, card_id in enumerate(card_encoder.classes_)}\n",
        "\n",
        "        # TF-IDF 특성 추출 및 추가\n",
        "        tfidf_features = []\n",
        "        for card_id in df['card_id']:\n",
        "            if card_id in card_id_to_idx:\n",
        "                card_idx = card_id_to_idx[card_id]\n",
        "                # 해당 카드의 TF-IDF 벡터 추출\n",
        "                tfidf_vector = card_features_matrix[card_idx].toarray().flatten()\n",
        "                tfidf_features.append(tfidf_vector)\n",
        "            else:\n",
        "                # 매핑되지 않는 카드는 0 벡터로 처리\n",
        "                tfidf_features.append(np.zeros(card_features_matrix.shape[1]))\n",
        "\n",
        "        # TF-IDF 특성을 DataFrame으로 변환\n",
        "        tfidf_df = pd.DataFrame(\n",
        "            tfidf_features,\n",
        "            columns=[f'tfidf_{i}' for i in range(card_features_matrix.shape[1])]\n",
        "        )\n",
        "\n",
        "        # 원본 데이터프레임과 TF-IDF 특성 결합\n",
        "        df = pd.concat([df, tfidf_df], axis=1)\n",
        "\n",
        "        # 모든 필요한 특성 컬럼이 데이터프레임에 있는지 확인\n",
        "        for col in feature_cols:\n",
        "            if col not in df.columns:\n",
        "                df[col] = 0.0\n",
        "\n",
        "        # 특성 추출 전에 feature_cols의 모든 컬럼이 df에 있는지 확인\n",
        "        for col in feature_cols:\n",
        "            if col not in df.columns:\n",
        "                print(f\"경고: 컬럼 '{col}'이 데이터프레임에 없습니다. 0으로 채웁니다.\")\n",
        "                df[col] = 0.0\n",
        "\n",
        "        # 특성 추출 - feature_cols에 정의된 컬럼만 사용\n",
        "        features = df[feature_cols]\n",
        "\n",
        "        # 디버깅 정보 출력\n",
        "        print(f\"prepare_deepfm_data: 특성 컬럼 수 = {len(feature_cols)}, 특성 행렬 크기 = {features.shape}\")\n",
        "\n",
        "        # 표준화\n",
        "        scaler = StandardScaler()\n",
        "        features = scaler.fit_transform(features)\n",
        "\n",
        "        # 모든 상호작용은 긍정적(1)으로 간주\n",
        "        labels = np.ones(len(df))\n",
        "\n",
        "        return features, labels, df\n",
        "\n",
        "    # DeepFM 모델 평가 함수 정의\n",
        "    def calculate_deepfm_hit_rate(test_data, model, n=10):\n",
        "        \"\"\"DeepFM Hit Rate 계산 - 전체 카드에 대해 예측하고 평가\"\"\"\n",
        "        hits = 0\n",
        "        total_users = 0\n",
        "\n",
        "        # 사용자별로 그룹화\n",
        "        unique_users = test_data['customer_id'].unique()\n",
        "\n",
        "        for customer_id in unique_users:\n",
        "            # 테스트 데이터에서 실제 상호작용한 카드\n",
        "            test_items = test_data[test_data['customer_id'] == customer_id]['card_id'].tolist()\n",
        "            if len(test_items) == 0:\n",
        "                continue\n",
        "\n",
        "            # 훈련 데이터에서 이미 사용자가 가진 카드\n",
        "            user_items = train_interactions[train_interactions['customer_id'] == customer_id]['card_id'].tolist()\n",
        "\n",
        "            # 사용자 프로필 정보 가져오기\n",
        "            user_profile = df_customer_profile[df_customer_profile['customer_id'] == customer_id]\n",
        "            if user_profile.empty:\n",
        "                continue\n",
        "\n",
        "            total_users += 1\n",
        "\n",
        "            # 전체 카드에 대해 예측 수행\n",
        "            all_cards = df_cards['card_id'].values\n",
        "            candidate_cards = [card for card in all_cards if card not in user_items]\n",
        "\n",
        "            # 사용자 특성 및 카드 특성 배치 준비\n",
        "            batch_features = []\n",
        "            for card_id in candidate_cards:\n",
        "                # 카드 특성 생성\n",
        "                card_type = 1 if card_id >= 1000 else 0\n",
        "                has_benefits = 1 if card_id in df_card_benefits['card_id'].values else 0\n",
        "\n",
        "                # 사용자 클러스터 정보\n",
        "                cluster = user_profile['cluster'].iloc[0]\n",
        "\n",
        "                # 특성 딕셔너리 생성 (기본 특성)\n",
        "                features_dict = {\n",
        "                    'card_type': card_type,\n",
        "                    'TOT_USE_AM': user_profile['TOT_USE_AM'].iloc[0],\n",
        "                    'has_benefits': has_benefits\n",
        "                }\n",
        "\n",
        "                # 클러스터에 대한 원-핫 인코딩 추가\n",
        "                for c in cluster_ids:\n",
        "                    col_name = f'cluster_{c}'\n",
        "                    features_dict[col_name] = 1 if cluster == c else 0\n",
        "\n",
        "                # TF-IDF 특성 추가\n",
        "                if card_id in card_id_to_idx:\n",
        "                    card_idx = card_id_to_idx[card_id]\n",
        "                    tfidf_vector = card_features_matrix[card_idx].toarray().flatten()\n",
        "                    for i, val in enumerate(tfidf_vector):\n",
        "                        features_dict[f'tfidf_{i}'] = val\n",
        "                else:\n",
        "                    for i in range(card_features_matrix.shape[1]):\n",
        "                        features_dict[f'tfidf_{i}'] = 0.0\n",
        "\n",
        "                # 특성 벡터 생성 - feature_cols에 정의된 모든 컬럼 사용\n",
        "                feature_vector = []\n",
        "                for col in feature_cols:\n",
        "                    feature_vector.append(features_dict.get(col, 0.0))\n",
        "\n",
        "                # 벡터 길이 확인\n",
        "                if len(feature_vector) != model.feature_dim:\n",
        "                    # 필요한 경우 벡터 길이 조정\n",
        "                    if len(feature_vector) < model.feature_dim:\n",
        "                        # 부족한 경우 0으로 채움\n",
        "                        feature_vector.extend([0.0] * (model.feature_dim - len(feature_vector)))\n",
        "                    else:\n",
        "                        # 넘치는 경우 자름\n",
        "                        feature_vector = feature_vector[:model.feature_dim]\n",
        "\n",
        "                batch_features.append(feature_vector)\n",
        "\n",
        "            # 배치로 예측\n",
        "            if batch_features:\n",
        "                batch_features_array = np.array(batch_features)\n",
        "                batch_scores = model.model.predict(batch_features_array, verbose=0).flatten()\n",
        "\n",
        "                # 카드 ID와 점수 연결\n",
        "                card_scores = list(zip(candidate_cards, batch_scores))\n",
        "\n",
        "                # 점수 기준으로 상위 N개 카드 선택\n",
        "                card_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "                recommended_items = [card_id for card_id, _ in card_scores[:n]]\n",
        "\n",
        "                # 상위 N개 중 실제 테스트 아이템이 있는지 확인\n",
        "                if len(np.intersect1d(recommended_items, test_items)) > 0:\n",
        "                    hits += 1\n",
        "\n",
        "        hit_rate = hits / total_users if total_users > 0 else 0\n",
        "        return hit_rate\n",
        "\n",
        "    # 클러스터별 모델과 평가 결과 저장\n",
        "    deepfm_models = {}\n",
        "    deepfm_hit_rates = {}\n",
        "\n",
        "    # DeepFM 모델의 특성 컬럼 목록 저장 (다른 함수에서 재사용)\n",
        "    feature_cols = ['card_type', 'TOT_USE_AM', 'has_benefits'] + \\\n",
        "                  [f'cluster_{c}' for c in cluster_ids] + \\\n",
        "                  [f'tfidf_{i}' for i in range(card_features_matrix.shape[1])]\n",
        "\n",
        "    # 전역 변수로 feature_dim 선언 (다른 함수에서 재사용)\n",
        "    global feature_dim\n",
        "    feature_dim = len(feature_cols)\n",
        "    print(f\"feature_cols 정의: {len(feature_cols)}개 특성\")\n",
        "\n",
        "    for cluster in cluster_ids:\n",
        "        print(f\"\\n클러스터 {cluster} DeepFM 모델 훈련 중...\")\n",
        "\n",
        "        # 클러스터에 해당하는 사용자 목록 추출\n",
        "        cluster_users = df_customer_profile[\n",
        "            df_customer_profile['cluster'] == cluster]['customer_id'].tolist()\n",
        "\n",
        "        if len(cluster_users) == 0:\n",
        "            deepfm_hit_rates[cluster] = 0\n",
        "            continue\n",
        "\n",
        "        # 클러스터별 훈련 및 테스트 데이터 추출\n",
        "        cluster_train_interactions = train_interactions[\n",
        "            train_interactions['customer_id'].isin(cluster_users)\n",
        "        ]\n",
        "\n",
        "        cluster_test_interactions = test_interactions[\n",
        "            test_interactions['customer_id'].isin(cluster_users)\n",
        "        ]\n",
        "\n",
        "        if len(cluster_train_interactions) == 0 or len(cluster_test_interactions) == 0:\n",
        "            deepfm_hit_rates[cluster] = 0\n",
        "            continue\n",
        "\n",
        "        # 클러스터별 훈련 데이터 준비\n",
        "        train_features, train_labels, train_df = prepare_deepfm_data(\n",
        "            cluster_train_interactions, df_customer_profile, card_features_matrix, card_encoder\n",
        "        )\n",
        "\n",
        "        test_features, test_labels, test_df = prepare_deepfm_data(\n",
        "            cluster_test_interactions, df_customer_profile, card_features_matrix, card_encoder\n",
        "        )\n",
        "\n",
        "        # 특성 차원 확인 및 조정\n",
        "        if train_features.shape[1] != feature_dim:\n",
        "            print(f\"경고: 특성 차원 불일치! 훈련 데이터 차원({train_features.shape[1]})이 모델 입력 차원({feature_dim})과 다릅니다.\")\n",
        "\n",
        "            # 더 작은 차원으로 맞추기\n",
        "            min_dim = min(train_features.shape[1], feature_dim)\n",
        "            if train_features.shape[1] > min_dim:\n",
        "                train_features = train_features[:, :min_dim]\n",
        "                test_features = test_features[:, :min_dim]\n",
        "\n",
        "            cluster_feature_dim = min_dim\n",
        "        else:\n",
        "            cluster_feature_dim = feature_dim\n",
        "\n",
        "        # 클러스터별 DeepFM 모델 초기화 및 훈련\n",
        "        cluster_deepfm_model = DeepFM(\n",
        "            feature_dim=cluster_feature_dim,\n",
        "            embedding_size=16,\n",
        "            dnn_hidden_units=[128, 64, 32]\n",
        "        )\n",
        "\n",
        "        # 조기 종료 콜백 정의\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        # 모델 훈련\n",
        "        print(f\"클러스터 {cluster} DeepFM 모델 훈련 시작...\")\n",
        "        cluster_deepfm_model.model.fit(\n",
        "            train_features,\n",
        "            train_labels,\n",
        "            epochs=30,\n",
        "            batch_size=256,\n",
        "            validation_split=0.1,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0\n",
        "        )\n",
        "        print(f\"클러스터 {cluster} DeepFM 모델 훈련 완료\")\n",
        "\n",
        "        # 모델 저장\n",
        "        deepfm_models[cluster] = cluster_deepfm_model\n",
        "\n",
        "        # 클러스터별 모델 평가\n",
        "        hit_rate = calculate_deepfm_hit_rate(test_df, cluster_deepfm_model)\n",
        "        deepfm_hit_rates[cluster] = hit_rate\n",
        "        print(f\"클러스터 {cluster} DeepFM Hit Rate: {hit_rate:.4f}\")\n",
        "else:\n",
        "    print(\"TensorFlow 라이브러리를 사용할 수 없어 훈련을 건너뜁니다.\")\n",
        "    deepfm_hit_rates = {}\n",
        "    deepfm_models = {}\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8. 클러스터별 최적 알고리즘 선택\n",
        "\n",
        "# %%\n",
        "# 클러스터별 최적 알고리즘 선택\n",
        "print(\"\\n클러스터별 최적 알고리즘 선택:\")\n",
        "\n",
        "best_model_by_cluster = {}\n",
        "for cluster in cluster_ids:\n",
        "    lightfm_hit_rate = lightfm_hit_rates.get(cluster, 0)\n",
        "    deepfm_hit_rate = deepfm_hit_rates.get(cluster, 0)\n",
        "\n",
        "    if lightfm_hit_rate > deepfm_hit_rate:\n",
        "        best_model = \"LightFM\"\n",
        "        hit_rate = lightfm_hit_rate\n",
        "    else:\n",
        "        best_model = \"DeepFM\"\n",
        "        hit_rate = deepfm_hit_rate\n",
        "\n",
        "    best_model_by_cluster[cluster] = (best_model, hit_rate)\n",
        "    print(f\"클러스터 {cluster}: {best_model} (Hit Rate: {hit_rate:.4f})\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 9. 고객별 추천 카드 생성\n",
        "\n",
        "# %%\n",
        "# 고객별 추천 카드 생성 함수\n",
        "def get_top_n_recommendations(model_type, customer_idx, customer_id, n=5):\n",
        "    \"\"\"상위 N개 추천 카드 생성\"\"\"\n",
        "    # 사용자 클러스터 확인\n",
        "    user_profile = df_customer_profile[df_customer_profile['customer_id'] == customer_id]\n",
        "    if user_profile.empty:\n",
        "        return []\n",
        "\n",
        "    user_cluster = user_profile['cluster'].iloc[0]\n",
        "\n",
        "    if model_type == \"LightFM\" and user_cluster in lightfm_models:\n",
        "        # 클러스터별 LightFM 모델 사용\n",
        "        lightfm_model = lightfm_models[user_cluster]\n",
        "\n",
        "        # 모든 카드에 대한 점수 예측\n",
        "        scores = lightfm_model.predict(\n",
        "            customer_idx,\n",
        "            np.arange(n_cards),\n",
        "            user_features=None,\n",
        "            item_features=card_features_matrix\n",
        "        )\n",
        "\n",
        "        # 이미 보유한 카드 제외\n",
        "        user_items = train_matrix[customer_idx].indices\n",
        "        scores[user_items] = -np.inf\n",
        "\n",
        "        # 상위 n개 선택\n",
        "        top_items = np.argsort(-scores)[:n]\n",
        "\n",
        "        # 카드 ID로 변환\n",
        "        top_cards = card_encoder.inverse_transform(top_items)\n",
        "        return top_cards\n",
        "\n",
        "    elif model_type == \"DeepFM\" and user_cluster in deepfm_models:\n",
        "        # 클러스터별 DeepFM 모델 사용\n",
        "        deepfm_model = deepfm_models[user_cluster]\n",
        "\n",
        "        # 추천할 수 있는 모든 카드 목록\n",
        "        all_cards = df_cards['card_id'].values\n",
        "\n",
        "        # 이미 보유한 카드 제외\n",
        "        user_cards = train_interactions[\n",
        "            train_interactions['customer_id'] == customer_id]['card_id'].tolist()\n",
        "        candidate_cards = [card for card in all_cards if card not in user_cards]\n",
        "\n",
        "        # 사용자 특성 및 카드 특성 배치 준비\n",
        "        batch_features = []\n",
        "        for card_id in candidate_cards:\n",
        "            # 카드 특성 생성\n",
        "            card_type = 1 if card_id >= 1000 else 0\n",
        "            has_benefits = 1 if card_id in df_card_benefits['card_id'].values else 0\n",
        "\n",
        "            # 사용자 클러스터 정보\n",
        "            cluster = user_profile['cluster'].iloc[0]\n",
        "\n",
        "            # 특성 딕셔너리 생성 (기본 특성)\n",
        "            features_dict = {\n",
        "                'card_type': card_type,\n",
        "                'TOT_USE_AM': user_profile['TOT_USE_AM'].iloc[0],\n",
        "                'has_benefits': has_benefits\n",
        "            }\n",
        "\n",
        "            # 클러스터에 대한 원-핫 인코딩 수동 추가\n",
        "            for c in cluster_ids:\n",
        "                col_name = f'cluster_{c}'\n",
        "                features_dict[col_name] = 1 if cluster == c else 0\n",
        "\n",
        "            # TF-IDF 특성 추가\n",
        "            if card_id in card_id_to_idx:\n",
        "                card_idx = card_id_to_idx[card_id]\n",
        "                tfidf_vector = card_features_matrix[card_idx].toarray().flatten()\n",
        "                for i, val in enumerate(tfidf_vector):\n",
        "                    features_dict[f'tfidf_{i}'] = val\n",
        "            else:\n",
        "                for i in range(card_features_matrix.shape[1]):\n",
        "                    features_dict[f'tfidf_{i}'] = 0.0\n",
        "\n",
        "            # 특성 벡터 생성 - feature_cols에 정의된 모든 컬럼 사용\n",
        "            feature_vector = []\n",
        "            for col in feature_cols:\n",
        "                feature_vector.append(features_dict.get(col, 0.0))\n",
        "\n",
        "            # 벡터 길이 확인\n",
        "            if len(feature_vector) != deepfm_model.feature_dim:\n",
        "                # 필요한 경우 벡터 길이 조정\n",
        "                if len(feature_vector) < deepfm_model.feature_dim:\n",
        "                    # 부족한 경우 0으로 채움\n",
        "                    feature_vector.extend([0.0] * (deepfm_model.feature_dim - len(feature_vector)))\n",
        "                else:\n",
        "                    # 넘치는 경우 자름\n",
        "                    feature_vector = feature_vector[:deepfm_model.feature_dim]\n",
        "\n",
        "            batch_features.append(feature_vector)\n",
        "\n",
        "        # 배치로 예측\n",
        "        if batch_features:\n",
        "            batch_features_array = np.array(batch_features)\n",
        "            batch_scores = deepfm_model.model.predict(batch_features_array, verbose=0).flatten()\n",
        "\n",
        "            # 카드 ID와 점수 연결\n",
        "            card_scores = list(zip(candidate_cards, batch_scores))\n",
        "\n",
        "            # 점수 기준으로 상위 N개 카드 선택\n",
        "            card_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "            top_cards = [card_id for card_id, _ in card_scores[:n]]\n",
        "            return top_cards\n",
        "\n",
        "        return []\n",
        "\n",
        "    return []\n",
        "\n",
        "# 고객별 추천 결과 저장\n",
        "print(\"\\n고객별 추천 카드 생성 중...\")\n",
        "recommendations = {}\n",
        "\n",
        "for _, customer in tqdm(df_customer_profile.iterrows(), total=len(df_customer_profile)):\n",
        "    customer_id = customer['customer_id']\n",
        "    if customer_id not in customer_id_to_idx:\n",
        "        continue\n",
        "\n",
        "    customer_idx = customer_id_to_idx[customer_id]\n",
        "    cluster = customer['cluster']\n",
        "\n",
        "    # 클러스터에 따른 최적 모델 선택\n",
        "    if cluster in best_model_by_cluster:\n",
        "        best_model = best_model_by_cluster[cluster][0]\n",
        "\n",
        "        # 추천 카드 생성\n",
        "        top_cards = get_top_n_recommendations(best_model, customer_idx, customer_id, n=5)\n",
        "\n",
        "        # 카드 이름으로 변환\n",
        "        card_names = [df_cards[df_cards['card_id'] == card_id]['card_name'].iloc[0]\n",
        "                     for card_id in top_cards if card_id in df_cards['card_id'].values.tolist()]\n",
        "\n",
        "        recommendations[customer_id] = card_names\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 10. 결과 저장 및 요약\n",
        "\n",
        "# %%\n",
        "# 추천 결과를 DataFrame으로 변환\n",
        "recommendations_list = []\n",
        "for customer_id, card_names in recommendations.items():\n",
        "    for i, card_name in enumerate(card_names, 1):\n",
        "        recommendations_list.append({\n",
        "            'customer_id': customer_id,\n",
        "            'rank': i,\n",
        "            'card_name': card_name\n",
        "        })\n",
        "\n",
        "df_recommendations = pd.DataFrame(recommendations_list)\n",
        "\n",
        "# 결과 저장\n",
        "df_recommendations.to_csv('card_recommendations.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"추천 결과가 card_recommendations.csv 파일로 저장되었습니다.\")\n",
        "\n",
        "# 결과 다운로드\n",
        "from google.colab import files\n",
        "files.download('card_recommendations.csv')\n",
        "\n",
        "# 구현 결과 요약\n",
        "print(\"\\n=== 카드 추천 시스템 구현 결과 ===\")\n",
        "print(f\"총 고객 수: {df_cus_card.shape[0]}\")\n",
        "print(f\"총 추천 고객 수: {len(recommendations)}\")\n",
        "print(f\"클러스터 수: {len(cluster_ids)}\")\n",
        "\n",
        "print(\"\\n클러스터별 최적 알고리즘:\")\n",
        "for cluster, (model, hit_rate) in best_model_by_cluster.items():\n",
        "    print(f\"클러스터 {cluster}: {model} (Hit Rate: {hit_rate:.4f})\")\n",
        "\n",
        "print(\"\\n추천 샘플 (5명):\")\n",
        "sample_recommendations = list(recommendations.items())[:5]\n",
        "for customer_id, card_names in sample_recommendations:\n",
        "    print(f\"고객 ID: {customer_id}\")\n",
        "    for i, card_name in enumerate(card_names, 1):\n",
        "        print(f\"  {i}. {card_name}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "018bbb6619ee455a9bde3f6e5d6f2f42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217736ea93ec46d183e0ec8b90fdaa82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38fa0b60ecb6433c8ab3db973f0da329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a35688a42e64125bf22fa5f8b67c2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6749d9e901f441e68df83b1293244867": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9c1d412c494a93959eb6863917b7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad3029bbb3b0437eabd71b33cbeebc94",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ae8c5401694ab08a70f1d83bf9145b",
            "value": "100%"
          }
        },
        "737ce19ab5774fa2b4468ae6c7a83620": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_018bbb6619ee455a9bde3f6e5d6f2f42",
            "placeholder": "​",
            "style": "IPY_MODEL_38fa0b60ecb6433c8ab3db973f0da329",
            "value": " 45955/45955 [09:20&lt;00:00, 117.68it/s]"
          }
        },
        "75dd5bf841fa4a61b30e3d4bee74dc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b9c1d412c494a93959eb6863917b7f5",
              "IPY_MODEL_dc053265641944509b5cdc276fb39db5",
              "IPY_MODEL_737ce19ab5774fa2b4468ae6c7a83620"
            ],
            "layout": "IPY_MODEL_6749d9e901f441e68df83b1293244867"
          }
        },
        "ad3029bbb3b0437eabd71b33cbeebc94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ae8c5401694ab08a70f1d83bf9145b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc053265641944509b5cdc276fb39db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217736ea93ec46d183e0ec8b90fdaa82",
            "max": 45955,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a35688a42e64125bf22fa5f8b67c2c0",
            "value": 45955
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
